#!/usr/bin/env python
# coding: utf-8

### Imports ###
import tensorflow as tf
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard
# from keras.engine.topology import Container
from keras.layers import *
from keras.models import Model,load_model
from keras.preprocessing import image
import keras.backend as K
import matplotlib.pyplot as plt
import numpy as np
import os
import random
import scipy.misc
from tqdm import *

#配置
MODEL_NAME = 'models/weights_final.hdf5'
DATA_DIR = "./../tiny-imagenet-200"
TRAIN_DIR = os.path.join(DATA_DIR, "train")
TEST_DIR = os.path.join(DATA_DIR, "test")
IMG_SHAPE = (64, 64)
# os.environ["CUDA_VISIBLE_DEVICES"] = "0"
TRAIN_DIR2 = './dataset'
# 超参数
beta = 1.0
# 训练
NB_EPOCHS = 1000
BATCH_SIZE = 1
# print(os.environ['CUDA_VISIBLE_DEVICES'])

# 加载数据集
def load_dataset_small(num_images_per_class_train=10, num_images_test=500):
    """Loads training and test datasets, from Tiny ImageNet Visual Recogition Challenge.

    Arguments:
        num_images_per_class_train: number of images per class to load into training dataset.
        num_images_test: total number of images to load into training dataset.
    """
    X_train = []
    X_test = []
    
    # Create training set.
    for c in os.listdir(TRAIN_DIR):
        c_dir = os.path.join(TRAIN_DIR, c, 'images')
        c_imgs = os.listdir(c_dir)
        random.shuffle(c_imgs)
        for img_name_i in c_imgs[0:num_images_per_class_train]:
            img_i = image.load_img(os.path.join(c_dir, img_name_i))
            x = image.img_to_array(img_i)
            X_train.append(x)
    random.shuffle(X_train)
    
    # Create test set.
    test_dir = os.path.join(TEST_DIR, 'images')
    test_imgs = os.listdir(test_dir)
    random.shuffle(test_imgs)
    for img_name_i in test_imgs[0:num_images_test]:
        img_i = image.load_img(os.path.join(test_dir, img_name_i))
        x = image.img_to_array(img_i)
        X_test.append(x)

    # Return train and test data as numpy arrays.
    return np.array(X_train), np.array(X_test)

def load_dataset_jack(num_images_per_class_train=10, num_images_test=500):
    X_train = []
    # Create training set.
    c_imgs = os.listdir(TRAIN_DIR2)
    random.shuffle(c_imgs)
    for img_name_i in c_imgs:
        img_i = image.load_img(os.path.join(TRAIN_DIR2, img_name_i))
        x = image.img_to_array(img_i)
        X_train.append(x)
    # random.shuffle(X_train)
    # Return train and test data as numpy arrays.
    return np.array(X_train)

# 模型构建
# Loss for reveal network
def rev_loss(s_true, s_pred):
    # Loss for reveal network is: beta * |S-S'|
    return beta * K.sum(K.square(s_true - s_pred))

# Loss for the full model, used for preparation and hidding networks
def full_loss(y_true, y_pred):
    # Loss for the full model is: |C-C'| + beta * |S-S'|
    s_true, c_true = y_true[...,0:3], y_true[...,3:6]
    s_pred, c_pred = y_pred[...,0:3], y_pred[...,3:6]
    
    s_loss = rev_loss(s_true, s_pred)
    c_loss = K.sum(K.square(c_true - c_pred))
    
    return s_loss + c_loss

# Returns the encoder as a Keras model, composed by Preparation and Hiding Networks.
def make_encoder(input_size):
    input_S = Input(shape=(input_size))
    input_C= Input(shape=(input_size))

    # Preparation Network
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_3x3')(input_S)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_4x4')(input_S)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_5x5')(input_S)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x = concatenate([input_C, x])
    
    # Hiding network
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid5_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    output_Cprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_C')(x)
    
    return Model(inputs=[input_S, input_C],
                 outputs=output_Cprime,
                 name = 'Encoder')

# Returns the decoder as a Keras model, composed by the Reveal Network
def make_decoder(input_size, fixed=False):
    
    # Reveal network
    reveal_input = Input(shape=(input_size))
    
    # Adding Gaussian noise with 0.01 standard deviation.
    input_with_noise = GaussianNoise(0.01, name='output_C_noise')(reveal_input)
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_3x3')(input_with_noise)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_4x4')(input_with_noise)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_5x5')(input_with_noise)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_3x3')(x)
    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_4x4')(x)
    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev5_5x5')(x)
    x = concatenate([x3, x4, x5])
    
    output_Sprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_S')(x)
    
    if not fixed:
        return Model(inputs=reveal_input,
                     outputs=output_Sprime,
                     name = 'Decoder')
    # else:
    #     return Container(inputs=reveal_input,
    #                      outputs=output_Sprime,
    #                      name = 'DecoderFixed')

# Full model.
def make_model(input_size):
    input_S = Input(shape=(input_size))
    input_C= Input(shape=(input_size))
    
    encoder = make_encoder(input_size)
    
    decoder = make_decoder(input_size)
    decoder.compile(optimizer='adam', loss=rev_loss)
    decoder.trainable = False
    
    output_Cprime = encoder([input_S, input_C])
    output_Sprime = decoder(output_Cprime)

    autoencoder = Model(inputs=[input_S, input_C],
                        outputs=concatenate([output_Sprime, output_Cprime]))
    autoencoder.compile(optimizer='adam', loss=full_loss)
    
    return encoder, decoder, autoencoder

# Although the author of the paper didn't explicitly described the learning rate schedule or the optimizer properties, we used our own schedule with ADAM optimizer. We train for 1000 epochs with a batch size of 32. 
def lr_schedule(epoch_idx):
    if epoch_idx < 200:
        return 0.001
    elif epoch_idx < 400:
        return 0.0003
    elif epoch_idx < 600:
        return 0.0001
    else:
        return 0.00003

def pixel_errors(input_S, input_C, decoded_S, decoded_C):
    """Calculates mean of Sum of Squared Errors per pixel for cover and secret images. """
    see_Spixel = np.sqrt(np.mean(np.square(255*(input_S - decoded_S))))
    see_Cpixel = np.sqrt(np.mean(np.square(255*(input_C - decoded_C))))
    
    return see_Spixel, see_Cpixel

def pixel_histogram(diff_S, diff_C):
    """Calculates histograms of errors for cover and secret image. """
    diff_Sflat = diff_S.flatten()
    diff_Cflat = diff_C.flatten()
    
    fig = plt.figure(figsize=(15, 5))
    a=fig.add_subplot(1,2,1)
        
    imgplot = plt.hist(255* diff_Cflat, 100, normed=1, alpha=0.75, facecolor='red')
    a.set_title('Distribution of error in the Cover image.')
    plt.axis([0, 250, 0, 0.2])
    
    a=fig.add_subplot(1,2,2)
    imgplot = plt.hist(255* diff_Sflat, 100, normed=1, alpha=0.75, facSecolor='red')
    a.set_title('Distribution of errors in the Secret image.')
    plt.axis([0, 250, 0, 0.2])
    
    plt.show()

def rgb2gray(rgb):
    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])

def show_image(img, n_rows, n_col, idx, gray=False, first_row=False, title=None):
    ax = plt.subplot(n_rows, n_col, idx)
    if gray:
        plt.imshow(rgb2gray(img), cmap = plt.get_cmap('gray'))
    else:
        plt.imshow(img)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    if first_row:
        plt.title(title)
#----------------------------------------------------------------------------
def load_dataset():
    # Load dataset.
    X_train_orig, X_test_orig = load_dataset_small()

    # Normalize image vectors.
    X_train = X_train_orig/255.
    X_test = X_test_orig/255.

    # Print statistics.
    print ("Number of training examples = " + str(X_train.shape[0]))
    print ("Number of test examples = " + str(X_train.shape[0]))
    print ("X_train shape: " + str(X_train.shape)) # Should be (train_size, 64, 64, 3)

    # We split training set into two halfs. First half is used for training as secret images, second half for cover images.
    # S: secret image
    input_S = X_train[0:X_train.shape[0] // 2]
    # C: cover image
    input_C = X_train[X_train.shape[0] // 2:]
    return input_S, input_C

def train():
    # Load dataset.
    # X_train_orig, X_test_orig = load_dataset_small()
    X_train_orig = load_dataset_jack()
    # Normalize image vectors.
    X_train = X_train_orig/255.

    # Print statistics.
    print ("Number of training examples = " + str(X_train.shape[0]))
    print ("Number of test examples = " + str(X_train.shape[0]))
    print ("X_train shape: " + str(X_train.shape)) # Should be (train_size, 64, 64, 3)

    # We split training set into two halfs. First half is used for training as secret images, second half for cover images.
    # S: secret image
    input_S = X_train[0:X_train.shape[0] // 2]
    # C: cover image
    input_C = X_train[X_train.shape[0] // 2:]

    # Show sample images from the training dataset
    fig=plt.figure(figsize=(8, 8))
    columns = 4
    rows = 5
    
    #显示样本
    for i in range(1, columns*rows +1):
        img_idx = np.random.choice(X_train.shape[0])
        fig.add_subplot(rows, columns, i)
        plt.imshow(X_train[img_idx])
    plt.show()

    #构建模型
    encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])

    m = input_S.shape[0]
    loss_history = []
    for epoch in range(NB_EPOCHS):
        np.random.shuffle(input_S)
        np.random.shuffle(input_C)
        
        t = tqdm(range(0, input_S.shape[0], BATCH_SIZE),mininterval=0)
        ae_loss = []
        rev_loss = []
        for idx in t:
            
            batch_S = input_S[idx:min(idx + BATCH_SIZE, m)]
            batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]
            
            C_prime = encoder_model.predict([batch_S, batch_C])
            
            ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S, batch_C],
                                                    y=np.concatenate((batch_S, batch_C),axis=3)))
            rev_loss.append(reveal_model.train_on_batch(x=C_prime,
                                                y=batch_S))
            
            # Update learning rate
            K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))
            K.set_value(reveal_model.optimizer.lr, lr_schedule(epoch))
            
            t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss)))
        loss_history.append(np.mean(ae_loss))

    # Plot loss through epochs
    plt.plot(loss_history)
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.show()

    # Save model
    autoencoder_model.save_weights('models/mymodel.hdf5')
    autoencoder_model.save('models/twopictures.hd5')

def evaluate(model_file):
    # Load evaluate model
    input_S, input_C = load_dataset()
    # Load model
    encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])
    autoencoder_model.load_weights(MODEL_NAME)
    
    autoencoder_model = load_model(model_file, custom_objects={'full_loss': full_loss})
    # autoencoder_model.save('model.hd5')
    # 性能评估
    # Retrieve decoded predictions.
    decoded = autoencoder_model.predict([input_S, input_C])
    decoded_S, decoded_C = decoded[...,0:3], decoded[...,3:6]

    # Get absolute difference between the outputs and the expected values.
    diff_S, diff_C = np.abs(decoded_S - input_S), np.abs(decoded_C - input_C) 

    # Print pixel-wise average errors in a 256 scale.
    S_error, C_error = pixel_errors(input_S, input_C, decoded_S, decoded_C)

    print ("S error per pixel [0, 255]:", S_error)
    print ("C error per pixel [0, 255]:", C_error)

    # Plot distribution of errors in cover and secret images.
    pixel_histogram(diff_S, diff_C)
#----------------------------------------------------------------------------
    # input_S, input_C = load_dataset()

    # # Configs for results display
    # # Show images in gray scale
    # SHOW_GRAY = False
    # # Show difference bettwen predictions and ground truth.
    # SHOW_DIFF = True
    # # Diff enhance magnitude
    # ENHANCE = 1

    # # Number of secret and cover pairs to show.
    # n = 6

    # plt.figure(figsize=(14, 15))
    # rand_indx = [random.randint(0, 1000) for x in range(n)]
    # # for i, idx in enumerate(range(0, n)):
    # for i, idx in enumerate(rand_indx):
    #     n_col = 6 if SHOW_DIFF else 4
        
    #     show_image(input_C[idx], n, n_col, i * n_col + 1, gray=SHOW_GRAY, first_row=i==0, title='Cover')

    #     show_image(input_S[idx], n, n_col, i * n_col + 2, gray=SHOW_GRAY, first_row=i==0, title='Secret')
        
    #     show_image(decoded_C[idx], n, n_col, i * n_col + 3, gray=SHOW_GRAY, first_row=i==0, title='Encoded Cover')
        
    #     show_image(decoded_S[idx], n, n_col, i * n_col + 4, gray=SHOW_GRAY, first_row=i==0, title='Decoded Secret')

        
    #     if SHOW_DIFF:
    #         show_image(np.multiply(diff_C[idx], ENHANCE), n, n_col, i * n_col + 5, gray=SHOW_GRAY, first_row=i==0, title='Diff Cover')
            
    #         show_image(np.multiply(diff_S[idx], ENHANCE), n, n_col, i * n_col + 6, gray=SHOW_GRAY, first_row=i==0, title='Diff Secret')

    # plt.show()
'''
def show():
    input_S, input_C = load_dataset()

    # Configs for results display
    # Show images in gray scale
    SHOW_GRAY = False
    # Show difference bettwen predictions and ground truth.
    SHOW_DIFF = True
    # Diff enhance magnitude
    ENHANCE = 1

    # Number of secret and cover pairs to show.
    n = 6

    plt.figure(figsize=(14, 15))
    rand_indx = [random.randint(0, 1000) for x in range(n)]
    # for i, idx in enumerate(range(0, n)):
    for i, idx in enumerate(rand_indx):
        n_col = 6 if SHOW_DIFF else 4
        
        show_image(input_C[idx], n, n_col, i * n_col + 1, gray=SHOW_GRAY, first_row=i==0, title='Cover')

        show_image(input_S[idx], n, n_col, i * n_col + 2, gray=SHOW_GRAY, first_row=i==0, title='Secret')
        
        show_image(decoded_C[idx], n, n_col, i * n_col + 3, gray=SHOW_GRAY, first_row=i==0, title='Encoded Cover')
        
        show_image(decoded_S[idx], n, n_col, i * n_col + 4, gray=SHOW_GRAY, first_row=i==0, title='Decoded Secret')

        
        if SHOW_DIFF:
            show_image(np.multiply(diff_C[idx], ENHANCE), n, n_col, i * n_col + 5, gray=SHOW_GRAY, first_row=i==0, title='Diff Cover')
            
            show_image(np.multiply(diff_S[idx], ENHANCE), n, n_col, i * n_col + 6, gray=SHOW_GRAY, first_row=i==0, title='Diff Secret')

    plt.show()
'''
def encode_singlepicture(secrit_img_path,cover_img_path,model_file):
    #图像读取
    secrit_img = image.load_img(secrit_img_path)
    secrit_img_array = image.img_to_array(secrit_img)
    cover_img = image.load_img(cover_img_path)
    cover_img_array = image.img_to_array(cover_img)
    x = []
    y = []
    x.append(secrit_img_array/255.)
    y.append(cover_img_array/255.)
    # print(x.shape)
    #模型加载
    # encoder_model, reveal_model, decode_model = make_model(x.shape)
    # decode_model.load_weights(MODEL_NAME)
    decode_model = load_model(model_file, custom_objects={'full_loss': full_loss})
    
    decoded = decode_model.predict([x, y])
    decoded_S, decoded_C = decoded[...,0:3], decoded[...,3:6]
    plt.figure(1)
    plt.subplot(212)
    plt.imshow(decoded_S[0])
    plt.subplot(211)
    plt.imshow(decoded_C[0])
    plt.savefig('result.jpg')
    plt.show()

def main():
    # train()
    # secrit_img_path = './dataset/qr.jpg'
    # cover_img_path = './dataset/s_img.jpg'
    secrit_img_path = './s_img.jpg'
    cover_img_path = './c_img.jpg'
    model_name = './models/twopictures.hd5'
    encode_singlepicture(secrit_img_path,cover_img_path,model_name)
    # evaluate(MODEL_NAME)

if __name__=='__main__':
    main()


